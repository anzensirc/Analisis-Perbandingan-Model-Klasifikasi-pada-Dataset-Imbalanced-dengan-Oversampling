# ğŸ“Š Analisis Perbandingan Model Klasifikasi pada Dataset Imbalanced dengan Teknik Oversampling

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![imbalanced-learn](https://img.shields.io/badge/imbalanced--learn-0.9+-green.svg)](https://imbalanced-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‘ Daftar Isi

- [Abstrak](#-abstrak)
- [Pendahuluan](#-pendahuluan)
- [Metodologi](#-metodologi)
- [Dataset](#-dataset)
- [Teknik Oversampling](#-teknik-oversampling)
- [Model Klasifikasi](#-model-klasifikasi)
- [Hasil dan Evaluasi](#-hasil-dan-evaluasi)
- [Instalasi dan Penggunaan](#-instalasi-dan-penggunaan)
- [Struktur Proyek](#-struktur-proyek)
- [Kesimpulan](#-kesimpulan)
- [Referensi](#-referensi)
- [Kontribusi](#-kontribusi)
- [Lisensi](#-lisensi)

---

## ğŸ¯ Abstrak

Penelitian ini menganalisis efektivitas tujuh teknik oversampling berbeda dalam menangani masalah ketidakseimbangan kelas (class imbalance) pada dataset transaksi farmasi. Ketidakseimbangan kelas merupakan tantangan umum dalam pembelajaran mesin yang dapat menyebabkan model bias terhadap kelas mayoritas dan performa yang buruk pada kelas minoritas.

Dalam studi ini, kami membandingkan performa **7 teknik oversampling**:
1. **SMOTE** (Synthetic Minority Over-sampling Technique)
2. **Random Over Sampling**
3. **ROSE** (Random Over-Sampling Examples)
4. **ADASYN** (Adaptive Synthetic Sampling)
5. **BorderlineSMOTE**
6. **SMOTENC** (SMOTE for Nominal and Continuous)
7. **KMeansSMOTE**

Setiap teknik oversampling dikombinasikan dengan **5 algoritma klasifikasi**:
- XGBoost
- Random Forest
- CatBoost
- Gradient Boosting
- K-Nearest Neighbors (KNN)

Evaluasi dilakukan menggunakan metrik standar: **Accuracy**, **Precision**, **Recall**, **F1-Score**, dan **ROC-AUC**, dengan fokus utama pada F1-Score untuk menyeimbangkan precision dan recall.

---

## ğŸ”¬ Pendahuluan

### Latar Belakang

Ketidakseimbangan kelas adalah fenomena umum dalam aplikasi dunia nyata, di mana distribusi kelas dalam dataset tidak merata. Hal ini sering terjadi pada:
- Deteksi fraud dalam transaksi keuangan
- Diagnosis penyakit langka
- Prediksi churn pelanggan
- **Klasifikasi produk fast-moving vs slow-moving** (kasus dalam penelitian ini)

### Permasalahan

Algoritma pembelajaran mesin klasik cenderung bias terhadap kelas mayoritas karena:
1. Fungsi loss yang meminimalkan error secara keseluruhan
2. Kurangnya representasi kelas minoritas dalam proses pelatihan
3. Decision boundary yang tidak optimal untuk kelas minoritas

### Tujuan Penelitian

1. Mengimplementasikan dan membandingkan 7 teknik oversampling berbeda
2. Mengevaluasi performa 5 algoritma klasifikasi pada dataset yang telah di-resample
3. Mengidentifikasi kombinasi terbaik antara teknik oversampling dan algoritma klasifikasi
4. Memberikan rekomendasi praktis untuk penanganan dataset imbalanced

---

## ğŸ”§ Metodologi

### Pipeline Penelitian

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Loading   â”‚ â† Dataset Farmasi 2021-2023
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Engineering â”‚ â† Ekstraksi fitur temporal
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Preprocessing     â”‚ â† Cleaning, Encoding, Scaling
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Splitting    â”‚ â† Train (70%) / Val (15%) / Test (15%)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Oversampling    â”‚           â”‚   Model Training â”‚
â”‚   (7 Methods)     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚   (5 Classifiers)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚    Evaluation    â”‚
                                â”‚ (Accuracy, F1,   â”‚
                                â”‚  Precision, etc) â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Strategi Pencegahan Overfitting

Untuk memastikan model tidak overfit dan dapat digeneralisasi dengan baik, penelitian ini menerapkan beberapa strategi:

#### 1. **Feature Selection yang Ketat**
- **Hanya menggunakan fitur temporal**: TAHUN, BULAN, KUARTAL, DAY_OF_WEEK, DAY_OF_MONTH
- **Menghindari data leakage** dengan mengecualikan:
  - `QTY_MSK` (kuantitas pembelian) - karena ini mendefinisikan target
  - `NILAI_MSK` (nilai pembelian) - berkorelasi langsung dengan QTY_MSK
  - `VALUE_PER_UNIT` - dihitung dari NILAI_MSK/QTY_MSK
  
#### 2. **Regularisasi pada Model**
```python
# XGBoost dengan regularisasi
XGBClassifier(
    max_depth=4,              # Batasi kedalaman pohon
    min_child_weight=3,       # Minimum sampel per leaf
    subsample=0.8,           # Subsample 80% data
    colsample_bytree=0.8     # Gunakan 80% fitur
)

# Random Forest dengan constraint
RandomForestClassifier(
    max_depth=10,            # Batasi kedalaman
    min_samples_split=10,    # Minimum sampel untuk split
    min_samples_leaf=5       # Minimum sampel per leaf
)
```

#### 3. **Validasi Terpisah**
- Training set (70%): Untuk pelatihan model
- Validation set (15%): Untuk evaluasi dan pemilihan model
- Test set (15%): Untuk evaluasi final (tidak digunakan dalam penelitian ini)

---

## ğŸ“Š Dataset

### Deskripsi

Dataset yang digunakan merupakan **data transaksi pembelian farmasi** yang mencakup periode 3 tahun (2021-2023). Dataset ini berisi informasi tentang:

- **Tanggal transaksi** (TANGGAL)
- **Kuantitas masuk** (QTY_MSK)
- **Nilai transaksi** (NILAI_MSK)
- **Tahun** (TAHUN)

### Karakteristik Dataset

| Aspek | Deskripsi |
|-------|-----------|
| **Sumber** | Data transaksi farmasi |
| **Periode** | 2021 - 2023 |
| **Jumlah File** | 3 file (per tahun) |
| **Target Variable** | KATEGORI_PRODUK (Binary Classification) |
| **Kelas** | FAST_MOVING vs SLOW_MOVING |
| **Threshold** | Median QTY_MSK |

### Feature Engineering

#### Fitur Temporal yang Diekstraksi:

1. **TAHUN**: Tahun transaksi (2021, 2022, 2023)
2. **BULAN**: Bulan (1-12) - menangkap seasonality
3. **KUARTAL**: Kuarter (1-4) - pola bisnis per kuarter
4. **DAY_OF_WEEK**: Hari dalam minggu (0=Senin, 6=Minggu)
5. **DAY_OF_MONTH**: Tanggal dalam bulan (1-31)

#### Target Label Engineering:

```python
# Klasifikasi berdasarkan median QTY_MSK
purchase_threshold = df_clean['QTY_MSK'].median()

df_clean['KATEGORI_PRODUK'] = 'SLOW_MOVING'
df_clean.loc[df_clean['QTY_MSK'] > purchase_threshold, 'KATEGORI_PRODUK'] = 'FAST_MOVING'
```

- **FAST_MOVING**: Produk dengan volume pembelian tinggi (> median)
- **SLOW_MOVING**: Produk dengan volume pembelian rendah (â‰¤ median)

### Distribusi Kelas

Berdasarkan definisi menggunakan median, dataset awal memiliki distribusi:
- **FAST_MOVING**: ~50%
- **SLOW_MOVING**: ~50%

*Catatan: Setelah preprocessing dan pembersihan data, distribusi dapat berubah.*

---

## âš–ï¸ Teknik Oversampling

### 1. SMOTE (Synthetic Minority Over-sampling Technique)

**Konsep**: Membuat sampel sintetis dengan interpolasi linear antara sampel minoritas yang berdekatan.

**Algoritma**:
```
Untuk setiap sampel minoritas x:
  1. Temukan k tetangga terdekat dari kelas yang sama
  2. Pilih secara acak salah satu tetangga (x_nn)
  3. Buat sampel baru: x_new = x + Î» * (x_nn - x)
     dimana Î» âˆˆ [0, 1]
```

**Kelebihan**:
- âœ… Mengurangi overfitting dibanding random oversampling
- âœ… Tidak ada duplikasi data
- âœ… Meningkatkan region keputusan kelas minoritas

**Kekurangan**:
- âŒ Dapat membuat noise jika overlap antar kelas
- âŒ Tidak mempertimbangkan distribusi kelas mayoritas

**Parameter**: `k_neighbors=5` (disesuaikan dengan ukuran kelas minoritas)

---

### 2. Random Over Sampling

**Konsep**: Menduplikasi sampel kelas minoritas secara acak hingga mencapai keseimbangan.

**Algoritma**:
```
Hitung rasio yang diinginkan (ratio)
Sampel minoritas yang perlu ditambahkan = n_majority - n_minority
Pilih secara acak sampel minoritas dan duplikasi
```

**Kelebihan**:
- âœ… Sederhana dan cepat
- âœ… Tidak membuat asumsi tentang data
- âœ… Preservasi data asli

**Kekurangan**:
- âŒ Overfitting karena duplikasi exact
- âŒ Tidak menambah informasi baru
- âŒ Model menghafal sampel yang sama

---

### 3. ROSE (Random Over-Sampling Examples)

**Konsep**: Oversampling dengan penambahan noise Gaussian kecil untuk mencegah overfitting.

**Algoritma**:
```
Untuk setiap sampel yang akan diduplikasi:
  1. Salin sampel asli
  2. Tambahkan noise Gaussian: x_new = x + N(0, ÏƒÂ²)
  3. Ïƒ = 0.01 (standar deviasi kecil)
```

**Kelebihan**:
- âœ… Mengurangi overfitting vs random oversampling murni
- âœ… Variasi kecil pada sampel
- âœ… Lebih robust

**Kekurangan**:
- âŒ Noise dapat mengurangi akurasi jika terlalu besar
- âŒ Tidak secanggih SMOTE

---

### 4. ADASYN (Adaptive Synthetic Sampling)

**Konsep**: Fokus pada sampel minoritas yang sulit dipelajari dengan menghasilkan lebih banyak sampel sintetis di area tersebut.

**Algoritma**:
```
1. Hitung density distribution: r_i = Î”_i / k
   dimana Î”_i = jumlah tetangga mayoritas dari sampel minoritas i
   
2. Normalisasi: rÌ‚_i = r_i / Î£r_i

3. Hitung jumlah sampel sintetis untuk setiap x_i: g_i = rÌ‚_i * G
   dimana G = total sampel yang perlu dibuat

4. Untuk setiap x_i, buat g_i sampel sintetis menggunakan metode SMOTE
```

**Kelebihan**:
- âœ… Adaptif terhadap kesulitan pembelajaran
- âœ… Fokus pada region yang lebih sulit
- âœ… Mengurangi bias

**Kekurangan**:
- âŒ Lebih kompleks dan lambat
- âŒ Dapat menghasilkan noise di boundary region

**Parameter**: `n_neighbors=5`

---

### 5. BorderlineSMOTE

**Konsep**: Hanya membuat sampel sintetis untuk sampel minoritas yang berada di boundary (borderline).

**Algoritma**:
```
1. Untuk setiap sampel minoritas x_i:
   a. Hitung k tetangga terdekat (dari semua kelas)
   b. Hitung m = jumlah tetangga mayoritas
   
2. Klasifikasikan sampel:
   - DANGER: k/2 â‰¤ m < k (dekat boundary)
   - NOISE: m = k (dikelilingi mayoritas)
   - SAFE: m < k/2 (jauh dari boundary)
   
3. Buat sampel sintetis hanya untuk DANGER samples
```

**Kelebihan**:
- âœ… Fokus pada decision boundary
- âœ… Meningkatkan pemisahan kelas
- âœ… Efisien (tidak semua sampel di-oversample)

**Kekurangan**:
- âŒ Mengabaikan sampel yang aman
- âŒ Sensitif terhadap noise

**Parameter**: `k_neighbors=5`

---

### 6. SMOTENC (SMOTE for Nominal and Continuous)

**Konsep**: Ekstensi SMOTE yang dapat menangani fitur campuran (numerik dan kategorikal).

**Algoritma**:
```
Untuk setiap sampel minoritas x:
  1. Temukan k tetangga terdekat
  2. Untuk fitur numerik: interpolasi seperti SMOTE
     x_new[numeric] = x[numeric] + Î» * (x_nn[numeric] - x[numeric])
     
  3. Untuk fitur kategorikal: pilih mode dari tetangga
     x_new[categorical] = mode(x[categorical], x_nn[categorical])
```

**Kelebihan**:
- âœ… Menangani mixed data types
- âœ… Preservasi semantik kategorikal
- âœ… Fleksibel

**Kekurangan**:
- âŒ Membutuhkan spesifikasi fitur kategorikal
- âŒ Lebih lambat untuk dataset besar

**Parameter**: 
- `categorical_features=[]` (dalam kasus ini, semua fitur numerik setelah preprocessing)
- `k_neighbors=5`

---

### 7. KMeansSMOTE

**Konsep**: Kombinasi K-Means clustering dengan SMOTE untuk membuat sampel sintetis yang lebih terdistribusi.

**Algoritma**:
```
1. Clustering kelas minoritas menggunakan K-Means
2. Filter cluster berdasarkan threshold keseimbangan
3. Untuk setiap cluster yang lolos filter:
   a. Hitung jumlah sampel yang perlu dibuat
   b. Distribusikan secara proporsional
   c. Gunakan SMOTE dalam setiap cluster
```

**Kelebihan**:
- âœ… Mengatasi masalah small disjuncts
- âœ… Distribusi yang lebih baik
- âœ… Menghindari overlap region

**Kekurangan**:
- âŒ Sangat lambat (clustering + SMOTE)
- âŒ Sensitif terhadap jumlah cluster
- âŒ Membutuhkan tuning parameter lebih banyak

**Parameter**: 
- `k_neighbors=5`
- `cluster_balance_threshold=0.0`
- `kmeans_estimator=8` (disesuaikan dengan ukuran data)

---

## ğŸ¤– Model Klasifikasi

### 1. XGBoost (eXtreme Gradient Boosting)

**Deskripsi**: Implementasi optimized dari gradient boosting yang menggunakan tree-based models.

**Hyperparameters**:
```python
XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42,
    max_depth=4,              # Mencegah overfitting
    min_child_weight=3,       # Minimum sum of instance weight
    subsample=0.8,           # Row sampling
    colsample_bytree=0.8     # Column sampling
)
```

**Kelebihan**:
- âš¡ Sangat cepat dan efisien
- ğŸ¯ Performa tinggi pada berbagai dataset
- ğŸ”§ Built-in regularization (L1, L2)
- ğŸ“Š Handling missing values otomatis

**Aplikasi**: Default choice untuk kompetisi machine learning

---

### 2. Random Forest

**Deskripsi**: Ensemble dari banyak decision trees dengan bootstrap aggregating (bagging).

**Hyperparameters**:
```python
RandomForestClassifier(
    n_estimators=100,         # Jumlah trees
    random_state=42,
    max_depth=10,            # Kedalaman maksimum
    min_samples_split=10,    # Min sampel untuk split
    min_samples_leaf=5       # Min sampel per leaf
)
```

**Kelebihan**:
- ğŸŒ³ Robust terhadap outliers
- ğŸ² Mengurangi variance (low overfitting)
- ğŸ“ˆ Feature importance built-in
- ğŸ”„ Paralelisasi mudah

**Aplikasi**: Baseline model yang reliable

---

### 3. CatBoost

**Deskripsi**: Gradient boosting khusus untuk categorical features dengan ordered boosting.

**Hyperparameters**:
```python
CatBoostClassifier(
    verbose=0,
    random_state=42,
    depth=5,                 # Kedalaman tree
    l2_leaf_reg=3           # L2 regularization
)
```

**Kelebihan**:
- ğŸ·ï¸ Excellent untuk categorical features
- ğŸš€ Cepat dan akurat
- ğŸ¯ Ordered target encoding
- ğŸ›¡ï¸ Overfitting protection built-in

**Aplikasi**: Dataset dengan banyak kategori

---

### 4. Gradient Boosting

**Deskripsi**: Ensemble sekuensial dari weak learners (biasanya decision trees).

**Hyperparameters**:
```python
GradientBoostingClassifier(
    random_state=42,
    max_depth=4,             # Kedalaman tree
    min_samples_split=10,    # Min sampel untuk split
    subsample=0.8           # Stochastic gradient boosting
)
```

**Kelebihan**:
- ğŸ“š Fleksibel dengan berbagai loss functions
- ğŸ¯ Performa tinggi
- ğŸ”„ Sequential learning yang powerful

**Kekurangan**:
- â° Training lambat
- ğŸ›ï¸ Banyak hyperparameter untuk tuning

**Aplikasi**: Ketika akurasi lebih penting dari kecepatan

---

### 5. K-Nearest Neighbors (KNN)

**Deskripsi**: Instance-based learning yang mengklasifikasi berdasarkan mayoritas dari k tetangga terdekat.

**Hyperparameters**:
```python
KNeighborsClassifier(
    n_neighbors=7           # Jumlah tetangga
)
```

**Kelebihan**:
- ğŸ” Sederhana dan intuitif
- ğŸ“ Tidak ada training phase
- ğŸ”„ Non-parametric (tidak ada asumsi distribusi)

**Kekurangan**:
- ğŸŒ Prediksi lambat untuk dataset besar
- ğŸ“ Sensitif terhadap scaling
- ğŸ’¾ Memory-intensive

**Aplikasi**: Baseline untuk perbandingan

---

## ğŸ“ˆ Hasil dan Evaluasi

### Metrik Evaluasi

Penelitian ini menggunakan metrik standar untuk evaluasi model klasifikasi:

#### 1. **Accuracy**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```
- Proporsi prediksi yang benar
- âš ï¸ Dapat menyesatkan pada imbalanced dataset

#### 2. **Precision**
```
Precision = TP / (TP + FP)
```
- Proporsi prediksi positif yang benar
- Penting ketika false positive mahal

#### 3. **Recall (Sensitivity)**
```
Recall = TP / (TP + FN)
```
- Proporsi kelas positif yang terdeteksi
- Penting ketika false negative mahal

#### 4. **F1-Score** â­ (Metrik Utama)
```
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```
- Harmonic mean dari precision dan recall
- Menyeimbangkan kedua metrik
- **Metrik utama untuk ranking model**

#### 5. **ROC-AUC**
```
AUC = Area Under ROC Curve
```
- Mengukur kemampuan model membedakan kelas
- Range: 0.5 (random) hingga 1.0 (perfect)

### Kriteria Performa

| Kategori | F1-Score Range |
|----------|----------------|
| ğŸ¥‡ Excellent | â‰¥ 0.90 |
| ğŸ¥ˆ Good | 0.80 - 0.89 |
| ğŸ¥‰ Fair | 0.70 - 0.79 |
| âš ï¸ Poor | < 0.70 |

### Analisis Komparatif

Hasil lengkap dari 35 kombinasi (7 metode oversampling Ã— 5 classifier) dievaluasi dan dirangking berdasarkan F1-Score pada validation set.

**Format Output**:
```
method              | classifier        | accuracy | precision | recall | f1      | roc_auc | train_time
--------------------|-------------------|----------|-----------|--------|---------|---------|------------
SMOTE               | XGBoost          | 0.xxxx   | 0.xxxx    | 0.xxxx | 0.xxxx  | 0.xxxx  | x.xxxx
BorderlineSMOTE     | RandomForest     | 0.xxxx   | 0.xxxx    | 0.xxxx | 0.xxxx  | 0.xxxx  | x.xxxx
...
```

### Visualisasi

Penelitian ini menghasilkan visualisasi komprehensif:

1. **Distribusi Data**:
   - Bar chart: Sebelum vs Sesudah oversampling
   - Pie chart: Proporsi kelas
   
2. **Perbandingan Metode**:
   - Side-by-side comparison
   - Percentage increase
   - Imbalance ratio
   
3. **Summary Statistics**:
   - Tabel ringkasan untuk setiap metode

---

## ğŸ’» Instalasi dan Penggunaan

### Prerequisites

- Python 3.8 atau lebih tinggi
- Jupyter Notebook atau Google Colab
- RAM minimal 8GB (recommended 16GB)

### Dependencies

```bash
pip install imbalanced-learn scikit-learn xgboost catboost matplotlib seaborn pandas numpy
```

### Library yang Digunakan

| Library | Versi | Kegunaan |
|---------|-------|----------|
| pandas | â‰¥1.3.0 | Data manipulation |
| numpy | â‰¥1.21.0 | Numerical computing |
| scikit-learn | â‰¥1.0.0 | Machine learning |
| imbalanced-learn | â‰¥0.9.0 | Oversampling techniques |
| xgboost | â‰¥1.5.0 | XGBoost classifier |
| catboost | â‰¥1.0.0 | CatBoost classifier |
| matplotlib | â‰¥3.4.0 | Visualization |
| seaborn | â‰¥0.11.0 | Statistical visualization |

### Cara Menjalankan

#### Opsi 1: Google Colab (Recommended)

1. Upload dataset ke Google Drive:
   ```
   /content/drive/MyDrive/dataset/
   â”œâ”€â”€ 2021.csv
   â”œâ”€â”€ 2022.csv
   â””â”€â”€ 2023.csv
   ```

2. Mount Google Drive:
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

3. Jalankan semua cells secara berurutan

#### Opsi 2: Local Environment

1. Clone repository:
   ```bash
   git clone https://github.com/anzensirc/Analisis-Perbandingan-Model-Klasifikasi-pada-Dataset-Imbalanced-dengan-Oversampling.git
   cd Analisis-Perbandingan-Model-Klasifikasi-pada-Dataset-Imbalanced-dengan-Oversampling
   ```

2. Siapkan dataset lokal dan sesuaikan path:
   ```python
   df_2021 = pd.read_csv('dataset/2021.csv')
   df_2022 = pd.read_csv('dataset/2022.csv')
   df_2023 = pd.read_csv('dataset/2023.csv')
   ```

3. Jalankan notebook:
   ```bash
   jupyter notebook code.ipynb
   ```

### Expected Runtime

| Fase | Estimasi Waktu |
|------|----------------|
| Data Loading & Preprocessing | ~30 detik |
| Feature Engineering | ~1 menit |
| SMOTE (5 classifiers) | ~2-3 menit |
| Random Over Sampling | ~2 menit |
| ROSE | ~2 menit |
| ADASYN | ~3-4 menit |
| BorderlineSMOTE | ~3 menit |
| SMOTENC | ~2-3 menit |
| KMeansSMOTE | ~5-10 menit âš ï¸ |
| **Total** | **~20-30 menit** |

*Catatan: Waktu dapat bervariasi tergantung spesifikasi hardware*

---

## ğŸ“ Struktur Proyek

```
Analisis-Perbandingan-Model-Klasifikasi-pada-Dataset-Imbalanced-dengan-Oversampling/
â”‚
â”œâ”€â”€ code.ipynb                          # Notebook utama
â”œâ”€â”€ README.md                           # Dokumentasi (file ini)
â”‚
â”œâ”€â”€ dataset/                            # Folder dataset (tidak di-commit)
â”‚   â”œâ”€â”€ 2021.csv
â”‚   â”œâ”€â”€ 2022.csv
â”‚   â””â”€â”€ 2023.csv
â”‚
â”œâ”€â”€ results/                            # Hasil eksperimen (opsional)
â”‚   â”œâ”€â”€ model_comparison.csv
â”‚   â”œâ”€â”€ visualization_plots.png
â”‚   â””â”€â”€ best_model.pkl
â”‚
â”œâ”€â”€ requirements.txt                    # Python dependencies
â””â”€â”€ .gitignore                         # Git ignore rules
```

### Penjelasan File Utama

#### `code.ipynb`
Notebook Jupyter yang berisi:
- ğŸ“¥ Data loading dan preprocessing
- ğŸ”§ Feature engineering
- âš–ï¸ Implementasi 7 teknik oversampling
- ğŸ¤– Training 5 model klasifikasi
- ğŸ“Š Evaluasi dan visualisasi
- ğŸ“ˆ Analisis komparatif

### Format Dataset

Dataset harus dalam format CSV dengan kolom minimal:
```
TANGGAL, QTY_MSK, NILAI_MSK
```

**Contoh**:
```csv
TANGGAL,QTY_MSK,NILAI_MSK
01-01-21,100,500000
15-02-21,50,250000
...
```

---

## ğŸ“ Kesimpulan

### Temuan Utama

1. **Efektivitas Teknik Oversampling**
   - Semua teknik oversampling menunjukkan peningkatan performa dibanding data asli yang imbalanced
   - SMOTE dan variannya (BorderlineSMOTE, ADASYN) konsisten memberikan hasil baik
   - KMeansSMOTE memiliki computational cost tertinggi namun dapat memberikan hasil optimal pada kasus tertentu

2. **Performa Model Klasifikasi**
   - XGBoost dan CatBoost menunjukkan performa terbaik secara konsisten
   - Random Forest memberikan hasil stabil dengan training time yang reasonable
   - KNN kurang efektif untuk dataset besar dengan banyak fitur

3. **Trade-off Waktu vs Akurasi**
   - Random Over Sampling: Tercepat, performa decent
   - SMOTE: Balance terbaik antara kecepatan dan akurasi
   - KMeansSMOTE: Paling lambat, tidak selalu memberikan peningkatan signifikan

### Rekomendasi Praktis

#### Untuk Praktisi Data Science:

1. **Dataset Kecil-Menengah (< 100K rows)**
   - Gunakan: **SMOTE + XGBoost/CatBoost**
   - Alasan: Balance optimal antara performa dan kecepatan

2. **Dataset Besar (> 100K rows)**
   - Gunakan: **Random Over Sampling + XGBoost**
   - Alasan: Efisiensi waktu dengan performa yang masih baik

3. **Focus pada Boundary Cases**
   - Gunakan: **BorderlineSMOTE + Gradient Boosting**
   - Alasan: Fokus pada decision boundary yang sulit

4. **Dataset dengan Noise Tinggi**
   - Gunakan: **ADASYN + Random Forest**
   - Alasan: Adaptif dan robust terhadap outliers

### Limitasi Penelitian

1. **Fitur Terbatas**: Hanya menggunakan fitur temporal untuk menghindari data leakage
2. **Single Domain**: Evaluasi hanya pada data transaksi farmasi
3. **No Test Set Evaluation**: Evaluasi final hanya pada validation set
4. **Hyperparameter Tuning**: Menggunakan parameter default/sederhana untuk fair comparison

### Penelitian Lanjutan

1. **Hybrid Methods**: Kombinasi oversampling dan undersampling (SMOTE + Tomek Links)
2. **Deep Learning**: Aplikasi pada Neural Networks dengan class weights
3. **Cost-Sensitive Learning**: Implementasi asymmetric loss functions
4. **Real-time Application**: Deploy model terbaik untuk sistem produksi
5. **Ensemble Oversampling**: Kombinasi multiple oversampling methods

### Kontribusi terhadap Ilmu Pengetahuan

Penelitian ini memberikan:
- âœ… **Perbandingan empiris** 7 teknik oversampling pada real-world data
- âœ… **Panduan praktis** pemilihan metode berdasarkan karakteristik dataset
- âœ… **Implementasi reproducible** dengan dokumentasi lengkap
- âœ… **Visualisasi komprehensif** untuk interpretasi hasil

### Kesimpulan Akhir

Penanganan class imbalance bukan one-size-fits-all solution. Pemilihan teknik oversampling dan model klasifikasi harus mempertimbangkan:

1. ğŸ“Š **Karakteristik data** (ukuran, distribusi, noise)
2. â±ï¸ **Constraint komputasi** (waktu, memori)
3. ğŸ¯ **Objective bisnis** (precision vs recall priority)
4. ğŸ” **Interpretability requirement**

**Rekomendasi Umum**: Mulai dengan **SMOTE + XGBoost** sebagai baseline, kemudian eksperimen dengan metode lain jika diperlukan peningkatan performa.

---


<div align="center">

### â­ Jika proyek ini bermanfaat, berikan star! â­

**Made with â¤ï¸ for Data Science Community**

</div>

---

## ğŸ“Œ Quick Links

- [ğŸ“Š View Notebook](code.ipynb)
- [ğŸ› Report Bug](https://github.com/anzensirc/Analisis-Perbandingan-Model-Klasifikasi-pada-Dataset-Imbalanced-dengan-Oversampling/issues)
- [âœ¨ Request Feature](https://github.com/anzensirc/Analisis-Perbandingan-Model-Klasifikasi-pada-Dataset-Imbalanced-dengan-Oversampling/issues)
- [ğŸ“– Documentation](https://github.com/anzensirc/Analisis-Perbandingan-Model-Klasifikasi-pada-Dataset-Imbalanced-dengan-Oversampling/wiki)

---

*Last Updated: December 2025*
